<!DOCTYPE html>
<html lang="en">
<head>

    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="Personal blog about x,y,z"/>
    <meta name="author" content="xrcyz">

    <!-- browser tab text -->  
    <title>xrcyz ¯\_(ツ)_/¯</title>
    <!-- style sheet -->
    <link href="../style.css" rel="stylesheet" type="text/css" media="all">
    <!-- font families -->
    <link href="https://fonts.googleapis.com/css2?family=Fira+Mono" rel="stylesheet">
    <!-- code highlighter -->
    <link rel="stylesheet" href="../assets/css/an-old-hope.min.css">
    <script src="../assets/js/highlight.min.js"></script>
    <script>hljs.highlightAll();</script>
</head>
  
  
  <body>
    <div id="page-container">  
      <div id="content-wrap">
        <!-- nav bar -->   
        <nav class="menu">
          <ul>
            <li><a href="../">Home</a></li>
            <li><a href="#">About</a></li>
            <li><a href="#">Contact</a></li>
            <!-- <li style="float:right"><a class="active" href="#">Login</a></li> -->
          </ul>
        </nav>
        
        <div id="content">
        
          <article>
            
            <header>
                <h1><a href="#">Neural Cellular Automata Writeup</a></h1>
                <time datetime="2022-04-24T13:00:00+00:00">April 24, 2022</time>
            </header>
            
            <p>About a year ago I decided that I would hand-weight a neural network in order to understand how it works. I felt like I could read all the matrix math and draw all the network diagrams and still have no idea why answers come out when inputs go in. I needed to strip and rebuild a neural network bolt by bolt, weight by weight, to see inside the forbidden blackbox.</p>
            
            <p>Since then I’ve made a <a href="../posts/NN-Boolean-Algebra.html">post</a> about my current mental model. I’m not going to cover that ground again. Instead I want to summarise my journey from Conway’s Game of Life to 3D rendering a neural reaction diffusion model.</p>
            
            <h2 id="conways-game-of-life">Conway’s Game of Life</h2>
            
            <p>I picked the update rule for Conway’s Game of Life because it was the simplest interesting program I could think of. If a cell is active and has 2 or 3 neighbors, it stays active. If an inactive cell has exactly 3 neighbors, then it activates. All other cells become inactive. From these simple rules we get the vast catalogue of patterns so far discovered.</p>
            
            <pre><code class="js">if(self == 1 && (neighbors == 2 || neighbors == 3)) return 1;
if(self == 0 && neighbors == 3) return 1;
else return 0;</code></pre>
            
            <p>We can represent this as a neural network <a href="https://openprocessing.org/sketch/1236584">like so</a>:</p>
            
            <pre><code class = "js">//input layer
let self, count; 

//layer 1
let selfIsOne = 1 /  (1 + exp(-10 * ( self  - 0.5 ))); 
let peersOver1 = 1 / (1 + exp(-10 * ( count - 1.5 ))); 
let peersOver2 = 1 / (1 + exp(-10 * ( count - 2.5 ))); 
let peersOver3 = 1 / (1 + exp(-10 * ( count - 3.5 ))); 

//layer 2
let self0peers3 =    1 / (1 + exp(-10 * (-selfIsOne + peersOver2 - peersOver3 - 0.5)));
let self1peers2or3 = 1 / (1 + exp(-10 * ( selfIsOne + peersOver1 - peersOver3 - 1.5)));

//output layer
let activation = 1 / (1 + exp(-10 * ( self0peers3 + self1peers2or3 - 0.5 ))); </code></pre>
            
            <p>Naturally I was curious to see what happens with different weights and biases, so I parameterised them and spent way to much time hitting refresh to explore the state space.</p>
            
            <p align="center">
                <a href="../p5/neural-game-of-life.html">
                    <img src="../assets/images/neural-games-of-life.png" alt="neural game of life screenshots" width="100%" align="middle" />
                </a>
            </p>
            
            <p>While exploring it occurred to me that the neural network can be plotted as a function <code class="language-plaintext highlighter-rouge">z = f(x,y)</code>, where <code class="language-plaintext highlighter-rouge">x</code> is the current cell state and <code class="language-plaintext highlighter-rouge">y</code> is the neighborhood sum. I could plot each rule set and, more importantly, reason about them as functional programs that map inputs to outputs. It feels much more natural to me to read a neural network as a tree of nested functions (output to input) than as a pipeline of operations (input to output).</p>
            
            <p>I started reading some shaders by <a href="https://openprocessing.org/user/254459?view=sketches">Paul Wheeler</a>, <a href="https://openprocessing.org/user/159668?view=sketches">Sayama</a>, <a href="https://openprocessing.org/user/161812?view=sketches">MathFoxLab</a> and others on OpenProcessing, and eventually hacked together a visualisation.</p>
            
            <p align="center">
                <a href="https://openprocessing.org/sketch/1254639">
                    <img src="../assets/images/NGOL-function-heatmap.png" alt="heatmap of cell states visited by neural network" width="100%" align="middle" />
                </a>
            </p>
            
            <p>The code in this <a href="https://openprocessing.org/sketch/1254639">sketch</a> is hot garbage, but its still kinda cool. You can select from a dozen or so cellular automatas and see the 3D plot of the neural network update rule, as well as a heatmap of states visited by a cell over time. The big takeaway that I got from this is that the weights and biases just push around slopes on a heightmap.</p>
            
            <p align="center">
                <img src="../assets/images/NGOL-function-plots.png" alt="neural networks plotted as 3D functions" width="100%" align="middle" />
            </p>
            
            <h2 id="multiple-neighborhood-cellular-automata">Multiple Neighborhood Cellular Automata</h2>
            
            <p>Drunk with power, I decided to add a third input to the neural network and try to imitate some of the <a href="https://www.youtube.com/watch?v=5TstDc_ed-4">outstanding results</a> created by <a href="https://slackermanz.com/understanding-multiple-neighborhood-cellular-automata/">Slackermanz</a>. Unfortunately I did not get C. elegans on the first go, but I did manage to get some motile cells and cell division, which was exciting.</p>
            
            <p align="center">
                <a href="../p5/multicellular-automata.html">
                    <img src="../assets/images/MNCA-cells.gif" alt="MNCA cellular automata" width="400" height="400" align="middle" />
                </a>
            </p>
            
            <h2 id="raymarching-3d-textures">Raymarching 3D textures</h2>
            
            <p>In Feb 2020 the article <a href="https://distill.pub/2020/growing-ca/">Growing Neural Cellular Automata</a> dropped on Distill, with its mind-blowing demonstration of cellular automata to regenerate images from a single pixel. Then in June 2021 the paper <a href="https://selforglive.github.io/alife_rd_textures/">Differentiable Programming of Reaction-Diffusion Patterns</a> showed examples of ‘volumetric texture synthesis’, where 2D update rules can be applied to spaces of higher dimensionality. I decided to try it.</p>
            
            <p>Up until this point I had been copying and pasting snippets of shader code without really understanding why they work. I took a detour through <a href="https://math.hws.edu/graphicsbook/index.html">Introduction to Computer Graphics</a> to learn the minimum OpenGL. Then I used the <a href="https://www.shadertoy.com/view/Ml3SD4">Volumetric Sandbox</a> by Flyguy as a template for raymarching 3D textures. I also referenced a lot of code from <a href="https://openprocessing.org/user/254459?view=sketches">Paul Wheeler</a> and <a href="https://openprocessing.org/user/67809?view=sketches">Dave Pagurek</a> on OpenProcessing.</p>
            
            <p>I’m still a novice shader programmer, but I’m happy with how it’s looking.</p>
            
            <p align="center">
                <img src="../assets/images/voxel reaction diffusion raymarching.png" alt="image of 3D reaction diffusion" width="100%" align="middle" />
            </p>
            
            <p>Which brings us to the current state of play: I expanded the cell neighborhoods to implement Young’s model of reaction diffusion. Each voxel receives an activation signal from an inner envelope and an inhibitor signal from an outer envelope. The neural network takes the current voxel state, the activation signal and the inhibitor signal, and computes a new voxel state.</p>
            
            <div style="position: relative; margin: 1.5em 0; padding-bottom: 56.25%;">
            <iframe style="position: absolute;" src="https://www.youtube.com/embed/8_6DYldEQ28" width="100%" height="100%" frameborder="0" allowfullscreen=""></iframe>
            </div>
            
            <p>What is interesting to me at present is that you could run reaction diffusion in a 3D texture in order to output a 2D video of cell mitosis. Time is just another dimension. Theoretically you could generate arbitrary rulesets for 2D cellular automata by training against a target 3D texture, right? Like, if you save the frames of an animation into a 3D texture, then you could use that as a target texture to train a neural cellular automata for video generation. And then do the same thing with a voxel scene by targeting a 4D texture. It’s turtles all the way up…</p>
            
            <p>If you read this far and you want to keep in contact, please give me a follow on <a href="https://twitter.com/planet403">Twitter</a>.</p>
            
            <h2 id="heroes">Heroes</h2>
            <p>Links to various people or channels who share awesome work.</p>
            
            <ul>
            <li><a href="https://www.youtube.com/channel/UCvjgXvBlbQiydffZU7m1_aw">Coding Train</a></li>
            <li><a href="https://openprocessing.org/user/159668?view=sketches">Sayama</a></li>
            <li><a href="https://openprocessing.org/user/161812?view=sketches">MathFoxLab</a></li>
            <li><a href="https://openprocessing.org/user/254459?view=sketches">Paul Wheeler</a></li>
            <li><a href="https://slackermanz.com/understanding-multiple-neighborhood-cellular-automata/">Slackermanz</a></li>
            <li><a href="https://twitter.com/ak92501/status/1465152668817670150">Alex Mordvintsev</a></li>
            <li><a href="https://www.shadertoy.com/view/Ml3SD4">Flyguy</a></li>
            <li><a href="https://softologyblog.wordpress.com/2019/12/28/3d-cellular-automata-3/">Softology blog</a></li>
            <li><a href="https://math.hws.edu/graphicsbook/index.html">David Eck</a></li>
            <li><a href="https://arxiv.org/abs/1812.05433">Bert Chan</a></li>
            </ul>
              
            
          </article>
          
        </div>
      </div>
      
      <footer id="footer">© 2022 xrcyz</footer>
      
  
    </div>
  </body>
  
  
</html>
